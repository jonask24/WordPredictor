{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L5: Semantic analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **word space model** of word meanings represents words as vectors in a high-dimensional vector space. In this lab you will experiment with a word space model which trained on the Swedish Wikipedia using [word2vec](https://code.google.com/archive/p/word2vec/). In order to use word2vec in Python, we use the [gensim](https://radimrehurek.com/gensim/) library.\n",
    "\n",
    "The library and some more essentials for this lab are contained in the module we load in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lt5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the lab system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load the pre-trained word space model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lt5.load_model(\"/home/TDDE17/labs/l5/data/wikipedia-sv.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consists of word vectors. In Python a word vector is represented as an [*array*](https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html). For the purposes of this lab, you can treat arrays as lists. The next line of code prints the vector for the word *student*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3891147 , -0.25333604,  0.10631166,  0.3614067 ,  0.14798231,\n",
       "       -0.28869128,  0.4014135 , -1.0192152 , -0.00860699,  0.7631522 ,\n",
       "       -0.30077016,  0.31991726, -0.3088756 , -0.21920508, -0.10915887,\n",
       "        0.4128209 , -0.23703265,  0.93853813,  0.8149459 ,  0.01140385,\n",
       "        0.24421778,  0.3621935 ,  0.4451298 ,  0.32729414,  0.82020354,\n",
       "       -0.7933065 , -0.044444  , -0.42768687, -0.8871227 ,  0.13306266,\n",
       "        0.57084686,  0.46596572, -0.48475036,  0.22611499,  0.3637679 ,\n",
       "        0.12183799,  0.7114298 ,  0.33212078,  1.3399355 , -0.78250617,\n",
       "       -0.6044599 ,  0.0656125 , -0.18711154,  0.7097786 ,  0.11466026,\n",
       "        0.36936972,  0.19929321, -0.41768453,  0.88794357, -0.49968722,\n",
       "       -0.53722715, -0.3276362 , -0.05238692, -0.21328461,  0.68021107,\n",
       "       -0.49659464,  0.78859437,  0.514551  ,  0.5988576 ,  0.31225756,\n",
       "       -0.4754915 ,  0.12143688,  0.79769266, -0.1092938 ,  0.05594372,\n",
       "        0.94904387,  1.1317161 , -0.236245  ,  0.3130332 , -0.4595733 ,\n",
       "        0.02605049,  1.0364265 ,  0.26993337, -0.01846636, -0.75967073,\n",
       "       -0.4102716 , -0.13498557,  0.43224856, -0.41064134, -0.4823403 ,\n",
       "        0.21146171,  0.07388449,  0.01523833, -0.26064622,  1.0480261 ,\n",
       "        0.55496365,  0.05995376,  0.39918602,  0.28152168,  0.13333985,\n",
       "        0.5695802 , -0.4568519 , -0.27244726,  0.17847468,  0.1403568 ,\n",
       "       -0.40522844, -0.9889807 , -0.41696772, -0.33668745,  0.5631273 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['student']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All vectors in the model have the same dimensionality $n$; this value is a parameter that is fixed when training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 1</div>\n",
    "<div class=\"panel-body\">\n",
    "Write some code that prints $n$ for the model we loaded earlier.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(model['student']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a word space model, we can compute the semantic similarity between words using the cosine distance between their respective word vectors. The next line of code showcases how to compute the cosine distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67229164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('student', 'lärare'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 2</div>\n",
    "<div class=\"panel-body\">\n",
    "<p>Write code to print the following:</p>\n",
    "<ul>\n",
    "<li>the cosine distance between some word of your liking and the word itself</li>\n",
    "<li>the cosine distance between two words that are, according to your judgement, semantically related</li>\n",
    "<li>the cosine distance between two words that are, according to your judgement, semantically unrelated</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n",
      "0.8446068\n",
      "0.35996804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('hej', 'hej'))\n",
    "print(model.similarity('ja', 'nej'))\n",
    "print(model.similarity('bord', 'jaga'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a word analogy task you are given two pairs of words that share a common semantic relation. A well-known example is *man/woman* and *king/queen*, where the semantic relation could be dubbed &lsquo;female&rsquo;. The task is to predict one of the words, e.g. *queen*, given the other three. By doing that we answer the question: &lsquo;*man* is to *woman* as *king* is to —?&rsquo;.\n",
    "\n",
    "### Predict the fourth word\n",
    "\n",
    "[Mikolov et al. (2013)](http://www.aclweb.org/anthology/N13-1090) have shown that the word analogy task can be solved by adding and substracting word vectors in a word2vec-model: the vector for *queen* is close (in terms of cosine distance) to the vector *king* $-$ *man* $+$ *woman*. In the next problem you will implement this idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 3</div>\n",
    "<div class=\"panel-body\">\n",
    "    \n",
    "Write a function `complete()` that takes the first three words of a word analogy quadruple as input and predicts the fourth word.\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "To solve the problem you should complete the following code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(model, a, b, c):\n",
    "    \"\"\"Returns the fourth word in the analogy quadruple\"\"\"\n",
    "    return model.most_similar(positive=[b, c], negative=[a])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is supposed to be called like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'drottning'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete(model, \"man\", \"kvinna\", \"kung\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve Problem&nbsp;3 you can use the following method of the model:\n",
    "\n",
    "`model.most_similar(pos, neg, n)`\n",
    "\n",
    "The method takes as its inputs two lists with words (strings), `pos` and `neg`, and a number `n`, and returns the `n` closest vectors to the vector that one gets by adding all the vectors in the `pos` list and subtracting all the vectors in the `neg` list. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('drottning', 0.7310913801193237)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar(['kung', 'kvinna'], ['man'], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories of analogies\n",
    "\n",
    "Word vectors are computed based on co-occurrence counts: words that co-occur frequently with certain other words are going to have similar vectors. In order to get a better understanding of the model&rsquo;s possibilities and limitations, we load a list of ten analogy pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = lt5.load_data(\"/home/729G17/labs/l5/data/analogies.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of `analogies` is a string consisting of four space-separated words. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tyskland\n"
     ]
    }
   ],
   "source": [
    "print(analogies[0].split(\" \")[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 4</div>\n",
    "<div class=\"panel-body\">\n",
    "<p>Write code that computes the model&rsquo;s accuracy on the task of predicting the fourth word in every analogy pair, given the other three. Feel free to use the <code>complete()</code> function that you implemented for Problem&nbsp;3.</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Use the next code cell to solve the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, analogies):\n",
    "    \"\"\"Computes the accuracy of the specified model on the specified list of analogy quadruples\"\"\"\n",
    "    count = 0\n",
    "    correctCount = 0\n",
    "    for i in range(0, len(analogies)):\n",
    "        if(complete(model, analogies[i].split(\" \")[0], \n",
    "                    analogies[i].split(\" \")[1], analogies[i].split(\" \")[2]) == analogies[i].split(\" \")[3]):\n",
    "            correctCount += 1\n",
    "        count += 1\n",
    "    return correctCount/count\n",
    "\n",
    "print(evaluate(model, analogies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 5</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>The analogies in the example file have been picked from ten different categories. Invent names for these categories. Which categories would you call semantic (related to the <em>meaning</em> of the words), which would you call syntactic (related to the <em>form</em> and the <em>grammatical behaviour</em> of the words)?</p>\n",
    "    <p>Select four categories, and find one new example for each of them. Of the four examples, two should be examples where the model succeeds in reproducing the intended analogy, and two should be examples where where the model fails to do so.</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Answer for Problem 5 by completing the following tables*\n",
    "\n",
    "<p><strong>Part 1: Naming the categories</strong></p>\n",
    "\n",
    "<table>\n",
    "    <tr><th>Example</th><th>Category</th></tr>\n",
    "    <tr><td>1</td><td>Huvudstad - Land</td></tr>\n",
    "    <tr><td>2</td><td>Landskap - Stad i landskapet</td></tr>\n",
    "    <tr><td>3</td><td>Land - Valuta</td></tr>\n",
    "    <tr><td>4</td><td>Land - Etnicitet</td></tr>\n",
    "    <tr><td>5</td><td>Kön - Familjerelation</td></tr>\n",
    "    <tr><td>6</td><td>Storlek - Ålder</td></tr>\n",
    "    <tr><td>7</td><td>Positiv - Komparativ</td></tr>\n",
    "    <tr><td>8</td><td>Positiv - Superlativ</td></tr>\n",
    "    <tr><td>9</td><td>Presens - Preteritum</td></tr>\n",
    "    <tr><td>10</td><td>Singular - Plural</td></tr>\n",
    "</table>\n",
    "\n",
    "<p><strong>Part 2: New examples for four of the categories</strong></p>\n",
    "\n",
    "<table>\n",
    "    <tr><th>Category</th><th>Example</th><th>Model&rsquo;s completion</th></tr>\n",
    "    <tr><td>0</td><td>man kvinna kung <em>drottning</em></td><td>man kvinna kung <em>drottning</em></td></tr>\n",
    "    <tr><td>1</td><td>Kina Peking Norge <em>Oslo</em></td><td>Kina Peking Norge <em>Lillehammer</em></td></tr>\n",
    "    <tr><td>3</td><td>USA USD UK <em>GBP</em></td><td>USA USD UK <em>Chart</em></td></tr>\n",
    "    <tr><td>4</td><td>Norge Norsk Mexiko <em>Mexikan</em></td><td>Norge Norsk Mexiko <em>Mexikos</em></td></tr>\n",
    "    <tr><td>10</td><td>Banan Bananer Boll <em>Bollar</em></td><td>Banan Bananer Boll <em>Stropp</em></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lillehammer\n",
      "Chart\n",
      "Mexikos\n",
      "Stropp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "words = ['Kina', 'Peking', 'Norge']\n",
    "print(complete(model, words[0], words[1], words[2]))\n",
    "words = ['USA', 'USD', 'UK']\n",
    "print(complete(model, words[0], words[1], words[2]))\n",
    "words = ['Norge', 'Norsk', 'Mexiko']\n",
    "print(complete(model, words[0], words[1], words[2]))\n",
    "words = ['Banan', 'Bananer', 'Boll']\n",
    "print(complete(model, words[0], words[1], words[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of word embeddings\n",
    "\n",
    "In the last problem of this lab, you will reflect on shortcomings of word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"panel panel-primary\">\n",
    "<div class=\"panel-heading\">Problem 6 (Reflection)</div>\n",
    "<div class=\"panel-body\">\n",
    "    <p>The lecture on word embeddings mentioned several shortcomings of the model. Design an experiment to find concrete examples that illustrate these shortcomings. Write a short reflection piece about your experience. Use the following prompts:</p>\n",
    "    <ul>\n",
    "        <li>How did you set up the experiment? What were the results?</li>\n",
    "        <li>Based on your previous knowledge, did you expect the results? How do you explain them?</li>\n",
    "        <li>What did you learn from this experiment? How, exactly, did you learn it? Why does this learning matter?</li>\n",
    "    </ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "måltavlorna\n",
      "Laurentien\n",
      "Ukraina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/TDDE17/labs/environment/lib/python3.4/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "words = ['Palestina', 'Palestinier', 'Israel']\n",
    "print(complete(model, words[0], words[1], words[2]))\n",
    "words = ['Svensk', 'Sverige', 'Kurd']\n",
    "print(complete(model, words[0], words[1], words[2]))\n",
    "words = ['Öland', 'Sverige', 'Krim']\n",
    "print(complete(model, words[0], words[1], words[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Då resultatet från word embedding är väldigt beroende av dess datamängd så kommer resultaten vara väldigt \"biased\" beroende på i vilka sammanhang som ord förekommer och även om det finns ett entydigt svar kommer att påverka. \n",
    "Vi tänkte därav testa \"kontroversiella\" anagram för att se resultaten och därav kunna avgöra hur väl algoritmen fungerar för dessa. Det vi tror kommer ske är att ord som påträffats i många olika sammanhang (och med olika innebörd/agenda) inte kommer att ha en hög säkerhet. \n",
    "För att välja ut anagram att testa har vi valt nutida konflikter då vi tror att dessa kommer att ha en större samplerate då de rimligtvis har större datamängder att utgå ifrån.\n",
    "\n",
    "De resultaten vi fick från de tre olika anagramen var inte helt osannolika men heller inte helt väntade. \n",
    "\n",
    "Det vi lärde oss från experimentet var hur mycket word embedding kan påverkas av sample-data, framförallt då det inte finns ett entydigt givet \"svar\" på anagrammet. Vi lärde oss detta från föreläsningen men vi fick resultat som påvisade detta utifrån egna tester. Detta är viktigt att tänka på om man ska bygga ett word-prediction program då det ofta inte är lämpligt att använda denna typ av funktion utan att ha någon av filter när ord anges som inte kan ge ett entydigt svar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <p>Once you have finished all problems, submit this notebook according to the instructions on the course web site.</p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
